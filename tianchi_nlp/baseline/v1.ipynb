{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "    assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "p_config = {'batch_size': 128, 'vocab_size': 8000,\n",
    "            'embedding_dim': 1024, 'epochs': 2, 'units': 256,\n",
    "            'max_inp': 1200, 'train_data': '/home/peihongyue/data/tianchi_nlp/train_set.csv',\n",
    "            'test_data': '/home/peihongyue/data/tianchi_nlp/test_a_sample_submit.csv',\n",
    "            'model_data': '/home/peihongyue/data/tianchi_nlp/model/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    y_array = []\n",
    "    x_array = []\n",
    "    with open(path) as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            line = line.split('\\t')\n",
    "            y_array.append(int(line[0]))\n",
    "            x_array.append([int(i) for i in line[1].split(' ')])\n",
    "    x_array = tf.keras.preprocessing.sequence.pad_sequences(x_array, maxlen=p_config['max_inp'], padding='post')\n",
    "    return x_array, np.array(y_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(1200,)),\n",
    "        tf.keras.layers.Embedding(8000, 1024),\n",
    "        tf.keras.layers.LSTM(256),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(14, activation='softmax')\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_test, y_test), callbacks=[callback], class_weight=class_weight)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(path):\n",
    "    x_array = []\n",
    "    with open(path) as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            x_array.append([int(i) for i in line.split(' ')])\n",
    "    x_array = tf.keras.preprocessing.sequence.pad_sequences(x_array, maxlen=p_config['max_inp'], padding='post')\n",
    "    return x_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 1200)\n",
      "(200000,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1200, 1024)        8192000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               1311744   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 14)                1806      \n",
      "=================================================================\n",
      "Total params: 9,538,446\n",
      "Trainable params: 9,538,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_data='/home/peihongyue/data/tianchi_nlp/train_set.csv'\n",
    "\n",
    "x_array, y_array = load_data(train_data)\n",
    "print(x_array.shape)\n",
    "print(y_array.shape)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "class_weight = {0: 38918, 1: 36945, 2: 31425, 3: 22133, 4: 15016, 5: 12232, 6: 9985, 7: 8841, 8: 7847, 9: 5878,\n",
    "                10: 4920, 11: 3131, 12: 1821, 13: 908}\n",
    "c_sum = sum(class_weight.values())\n",
    "class_weight = {key: (1 / val) * (c_sum) / 2.0 for key, val in class_weight.items()}\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_array, y_array, test_size=0.3)\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0802 17:39:13.051182 140636824545024 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "W0802 17:39:13.294522 140636824545024 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "140000/140000 [==============================] - 709s 5ms/sample - loss: 16.6960 - accuracy: 0.1526 - val_loss: 16.5371 - val_accuracy: 0.1693\n",
      "Epoch 2/20\n",
      "140000/140000 [==============================] - 705s 5ms/sample - loss: 9.1700 - accuracy: 0.5519 - val_loss: 4.1831 - val_accuracy: 0.7968\n",
      "Epoch 3/20\n",
      "140000/140000 [==============================] - 707s 5ms/sample - loss: 3.1566 - accuracy: 0.8519 - val_loss: 2.9122 - val_accuracy: 0.8723\n",
      "Epoch 4/20\n",
      "140000/140000 [==============================] - 707s 5ms/sample - loss: 2.2380 - accuracy: 0.8892 - val_loss: 2.4071 - val_accuracy: 0.8874\n",
      "Epoch 5/20\n",
      "140000/140000 [==============================] - 708s 5ms/sample - loss: 1.7413 - accuracy: 0.9094 - val_loss: 2.1440 - val_accuracy: 0.9122\n",
      "Epoch 6/20\n",
      "140000/140000 [==============================] - 706s 5ms/sample - loss: 1.3821 - accuracy: 0.9239 - val_loss: 2.0383 - val_accuracy: 0.9171\n",
      "Epoch 7/20\n",
      "140000/140000 [==============================] - 706s 5ms/sample - loss: 1.1996 - accuracy: 0.9313 - val_loss: 2.1072 - val_accuracy: 0.9139\n",
      "Epoch 8/20\n",
      "140000/140000 [==============================] - 707s 5ms/sample - loss: 1.0080 - accuracy: 0.9392 - val_loss: 2.1020 - val_accuracy: 0.9179\n",
      "Epoch 9/20\n",
      "140000/140000 [==============================] - 707s 5ms/sample - loss: 0.9147 - accuracy: 0.9444 - val_loss: 2.1075 - val_accuracy: 0.9173\n",
      "Epoch 10/20\n",
      "140000/140000 [==============================] - 708s 5ms/sample - loss: 0.7851 - accuracy: 0.9504 - val_loss: 2.0952 - val_accuracy: 0.9201\n",
      "Epoch 11/20\n",
      "140000/140000 [==============================] - 708s 5ms/sample - loss: 0.6481 - accuracy: 0.9566 - val_loss: 2.3476 - val_accuracy: 0.9193\n",
      "Epoch 12/20\n",
      "140000/140000 [==============================] - 708s 5ms/sample - loss: 0.5961 - accuracy: 0.9599 - val_loss: 2.5670 - val_accuracy: 0.9186\n",
      "Epoch 13/20\n",
      "140000/140000 [==============================] - 707s 5ms/sample - loss: 0.5241 - accuracy: 0.9639 - val_loss: 2.4649 - val_accuracy: 0.9197\n",
      "[1 4 0 ... 2 4 0]\n",
      "[1 4 0 ... 2 3 0]\n",
      "0.9023111959019949\n"
     ]
    }
   ],
   "source": [
    "model = train(model, x_train, y_train, x_test, y_test)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = tf.argmax(y_pred, axis=1).numpy()\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "\n",
    "print(f1_score(y_pred, y_test, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data='/home/peihongyue/data/tianchi_nlp/test_a.csv'\n",
    "test_x = load_test(test_data)\n",
    "y_pred = model.predict(test_x)\n",
    "y_pred = tf.argmax(y_pred, axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 8 ... 1 3 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/peihongyue/data/tianchi_nlp/ans1.csv', 'w') as f:\n",
    "    f.write('label' + '\\n')\n",
    "    for y in y_pred:\n",
    "        f.write(str(y) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5399, 3117, 1070, ...,    0,    0,    0],\n",
       "       [6819,  648, 3523, ..., 3215, 5791, 2662],\n",
       "       [2673, 5076, 6835, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [3770, 2461, 2151, ...,    0,    0,    0],\n",
       "       [6235, 6248, 5620, ...,    0,    0,    0],\n",
       "       [1141, 4411, 6902, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
